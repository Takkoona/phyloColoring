{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "The `H3N2 HA` and `H1N1 HA` sequences of `Human` host flu virus were downloaded from https://www.fludb.org/. Copy the sequence file to the destination folder under `Trees`. Will possibly have quality check on the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "SEQUENCES_DIR = \"Sequences\"\n",
    "METADATA_DIR = \"Metadata\"\n",
    "TREES_DIR = \"Trees\"\n",
    "\n",
    "H1N1_HA_NAME = \"H1N1_HA\"\n",
    "H3N2_HA_NAME = \"H3N2_HA\"\n",
    "GROUPING = \"Spatiotemporal\"\n",
    "\n",
    "H1N1_HA_TREE_DIR = os.path.join(TREES_DIR, H1N1_HA_NAME)\n",
    "H3N2_HA_TREE_DIR = os.path.join(TREES_DIR, H3N2_HA_NAME)\n",
    "H1N1_HA_GROUPING_DIR = os.path.join(H1N1_HA_TREE_DIR, GROUPING)\n",
    "H3N2_HA_GROUPING_DIR = os.path.join(H3N2_HA_TREE_DIR, GROUPING)\n",
    "\n",
    "H1N1_HA_YEAR = 2009\n",
    "H3N2_HA_YEAR = 2009\n",
    "\n",
    "MAX_AMBIGUITY = 1\n",
    "HA_STANDARD_LEN = 566\n",
    "AMBIGUITY = r\"B|J|Z\"\n",
    "\n",
    "H1N1_HA_EXCLUDE = [\n",
    "    \"CY075897\",\n",
    "    \"JX875001\",\n",
    "    \"JQ348837\",\n",
    "    \"KU720432\",\n",
    "    \"KU720436\",\n",
    "    \"KU720435\",\n",
    "    \"KY930507\",\n",
    "    \"MK615191\",\n",
    "    \"CY079544\",\n",
    "    \"KF057112\",\n",
    "    \"HQ908440\",\n",
    "    \"MH211234\",\n",
    "    \"MH211235\",\n",
    "]\n",
    "\n",
    "H3N2_HA_EXCLUDE = [\n",
    "    \"KY273064\",\n",
    "    \"KY273063\",\n",
    "    \"KY273058\",\n",
    "    \"KY273060\",\n",
    "    \"KY273057\",\n",
    "    \"KU289634\",\n",
    "    \"MH201523\",\n",
    "    \"KP335956\",\n",
    "    \"KF805696\",\n",
    "    \"KP335932\",\n",
    "    \"KP335938\",\n",
    "    \"KP335934\",\n",
    "    \"MK239073\",\n",
    "    \"MK117070\",\n",
    "    \"KJ955515\",\n",
    "    \"KP765772\",\n",
    "    \"KJ623709\",\n",
    "    \"GU937743\",\n",
    "    \"KF805640\",\n",
    "    \"KF805656\",\n",
    "    \"KF805688\",\n",
    "    \"KU182657\",\n",
    "    \"MF993038\",\n",
    "    \"KU182655\",\n",
    "    \"MG856267\",\n",
    "    \"MN571199\",\n",
    "    \"CY189823\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 27\n"
     ]
    }
   ],
   "source": [
    "print(len(H1N1_HA_EXCLUDE), len(H3N2_HA_EXCLUDE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TREES_DIR):\n",
    "    os.mkdir(TREES_DIR)\n",
    "\n",
    "if os.path.exists(H1N1_HA_GROUPING_DIR):\n",
    "    shutil.rmtree(H1N1_HA_GROUPING_DIR)\n",
    "os.makedirs(H1N1_HA_GROUPING_DIR)\n",
    "    \n",
    "if os.path.exists(H3N2_HA_GROUPING_DIR):\n",
    "    shutil.rmtree(H3N2_HA_GROUPING_DIR)\n",
    "os.makedirs(H3N2_HA_GROUPING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. H1N1 metadata and quality check\n",
    "\n",
    "Remove the sequence with ambiguious sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\n",
    "    os.path.join(METADATA_DIR, H1N1_HA_NAME + \".tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    index_col=\"Sequence Accession\",\n",
    "    na_values=[\"-N/A-\", \"Unknown\"],\n",
    "    true_values=[\"Yes\"],\n",
    "    false_values=[\"No\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19735\n"
     ]
    }
   ],
   "source": [
    "nQualified = 0\n",
    "seqs = defaultdict(list)\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(SEQUENCES_DIR, H1N1_HA_NAME + \".fasta\"), \"fasta\"):\n",
    "    info = dict(i.split(':') for i in record.id.split('|'))\n",
    "    time = meta.loc[info[\"gb\"], \"Collection Date\"]\n",
    "    time = time[-4:] if pd.notna(time) else 0\n",
    "    record.seq = Seq(re.sub(AMBIGUITY, 'X', str(record.seq)))\n",
    "#     country = meta.loc[info[\"gb\"], \"Country\"]\n",
    "#     country = country.replace(' ', '_') if pd.notna(country) else \"Unknown\"\n",
    "    if (\n",
    "        info[\"gb\"] not in H1N1_HA_EXCLUDE and \n",
    "        int(time) >= H1N1_HA_YEAR and\n",
    "        Counter(str(record.seq))['X'] < MAX_AMBIGUITY and \n",
    "        len(record.seq) == HA_STANDARD_LEN\n",
    "    ):\n",
    "        nQualified += 1\n",
    "        record.id = info[\"gb\"]\n",
    "        record.description = \"\"\n",
    "        seqs[\"{}\".format(time)].append(record)\n",
    "    \n",
    "for st, records in seqs.items():\n",
    "    outDir = os.path.join(H1N1_HA_GROUPING_DIR, st)\n",
    "    if not os.path.exists(outDir):\n",
    "        os.mkdir(outDir)\n",
    "    SeqIO.write(records, os.path.join(outDir, \"sequences.fasta\"), \"fasta\")\n",
    "print(nQualified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. H3N2 metadata and quality check\n",
    "\n",
    "Remove the sequence with ambiguious sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\n",
    "    os.path.join(METADATA_DIR, H3N2_HA_NAME + \".tsv\"),\n",
    "    sep=\"\\t\",\n",
    "    na_values=[\"-N/A-\", \"Unknown\"],\n",
    "    true_values=[\"Yes\"],\n",
    "    false_values=[\"No\"]\n",
    ")\n",
    "meta = meta.drop_duplicates()\n",
    "meta = meta.set_index(\"Sequence Accession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23261\n"
     ]
    }
   ],
   "source": [
    "nQualified = 0\n",
    "seqs = defaultdict(list)\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(SEQUENCES_DIR, H3N2_HA_NAME + \".fasta\"), \"fasta\"):\n",
    "    info = dict(i.split(':') for i in record.id.split('|'))\n",
    "    time = meta.loc[info[\"gb\"], \"Collection Date\"]\n",
    "    time = time[-4:] if pd.notna(time) else 0\n",
    "    record.seq = Seq(re.sub(AMBIGUITY, 'X', str(record.seq)))\n",
    "    if (\n",
    "        info[\"gb\"] not in H3N2_HA_EXCLUDE and \n",
    "        int(time) >= H3N2_HA_YEAR and \n",
    "        Counter(str(record.seq))['X'] < MAX_AMBIGUITY and\n",
    "        len(record.seq) == HA_STANDARD_LEN\n",
    "    ):\n",
    "        nQualified += 1\n",
    "        record.id = info[\"gb\"]\n",
    "        record.description = \"\"\n",
    "        seqs[\"{}\".format(time)].append(record)\n",
    "    \n",
    "for st, records in seqs.items():\n",
    "    outDir = os.path.join(H3N2_HA_GROUPING_DIR, st)\n",
    "    if not os.path.exists(outDir):\n",
    "        os.mkdir(outDir)\n",
    "    SeqIO.write(records, os.path.join(outDir, \"sequences.fasta\"), \"fasta\")\n",
    "print(nQualified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in os.listdir(SEQUENCES_DIR):\n",
    "#     dstDir = os.path.join(TREES_DIR, os.path.splitext(fname)[0])\n",
    "#     if not os.path.exists(dstDir):\n",
    "#         os.mkdir(dstDir)\n",
    "#     shutil.copyfile(\n",
    "#         os.path.join(SEQUENCES_DIR, fname),\n",
    "#         os.path.join(dstDir, \"sequences.fasta\")\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
